%!TEX root = ../main.tex

\chapter{Introduction}%
\label{chap:introduction}

Since its first direct detection in 1965~\cite{Cowan1956}, physicists have shed light on
many mysteries involving the neutrino, one of the most elusive elementary particles ever
observed. Since the discovery of neutrino oscillations, an evidence of their tiny but
non-zero mass, the field has been progressively acquiring importance in the scientific
community as being able to test the most fundamental laws of physics. The neutrino being a
massive particle already represents a crack in the minimal formulation of the Standard
Model of particle physics, in which the neutrino, just as the photon, is a massless
particle. The unrevealed fundamental nature of its mass, however, might veil a more
revolutionary discovery, that the our Standard Model, which has proved to be incredibly
successful in describing the Nature we know, is just a part of a broader scheme.
\newpar
What such a tiny mass could be possibly hiding? Physicists have always been puzzled by the
arbitrarily diverging mass scales in the Standard Model. The electron neutrino is more
than one million times lighter than the electron itself, and we believe that it is not by
chance: a more general theory must exist to explain it. Theorists have formulated a
plethora of models, which usually foresee the existence of new fundamental particles, in
attempt to unveil the underlying picture. No conclusive experimental evidence, however,
has been reported in favor of any of these theories. In perhaps the simplest model
explaining the neutrino mass scale, heavy neutrino counterparts provide the suppression
factor in the theory necessary to give the neutrino such a small mass. Unfortunately, the
energies at which these hypothetical heavy particles can be directly detected is far from
being reachable with current experimental technologies. The mass the neutrino acquires
through this mechanism is called \emph{Majorana} mass from the Italian physicist who first
proposed this type of particles, Ettore Majorana~\cite{Majorana1932}. The reason why
Majorana neutrinos are so popular is now evident: small masses probe higher energy scale
physics.
\newpar
How to experimentally test if the neutrino is a Majorana particle? An extremely rare
nuclear process, the so-called neutrinoless double-beta decay, has been identified by
physicists as the most promising discovery channel. Certain atomic nuclei have been
observed to undergo a double-beta decay, i.e.~the occurrence of two simultaneous beta
decays, in which two electrons and two electron anti-neutrinos are emitted. The rate of
this process is extremely low: the probability for one of these nuclei to decay in a time
equal to the age of the universe is less than one over one billionth ore more, depending
on the nucleus. Theoreticians have demonstrated that, if the neutrino is a Majorana
particle, another double-beta decay mode can take place, in which no neutrinos are
produced at all. The experimental signature of this hypothesized neutrinoless double-beta
decay mode is therefore the emission of two electrons, at the maximum energy available in
the process.
\newpar
\begin{center}
  \begin{tikzpicture}[font=\small]
    \node at (0,0) {\includegraphics[width=0.6\textwidth]{bb-artist.png}};

    \node[align=center] at (-3.5,-1.9) {\scshape $\upbeta$ decay};
    \node[align=center] at ( 0.0,-1.9) {\scshape double-$\upbeta$ decay};
    \node[align=center] at ( 3.5,-1.9) {\scshape neutrinoless \\ \scshape double-$\upbeta$ decay};

    \node at (-4.3, 1.5) {$e^-$};
    \node at (-2.2,-1.1) {\footnotesize $\overline{\upnu}_e$};

    \node at (-1.2, 1.1) {$e^-$};
    \node at ( 1.4, 1.2) {$e^-$};
    \node at ( 1.3,-1.0) {\footnotesize $\overline{\upnu}_e$};
    \node at (-1.5,-0.9) {\footnotesize $\overline{\upnu}_e$};

    \node at ( 3.2, 1.5) {$e^-$};
    \node at ( 4.6,-1.2) {$e^-$};
  \end{tikzpicture}
\end{center}
In addition to be inevitably tied to the origins of the neutrino mass, neutrinoless
double-beta decay has a second critical consequence on the fundamental laws of Nature. One
of the crucial conserved symmetries in the Standard Model concerns matter and anti-matter:
in all processes they must be produced, or destroyed, in the same amount.  The world we
know, however, is evidently made of matter --- and cosmological observations seem to
confirm that the rest of the universe looks very similar. How can it be that all the
balancing anti-matter predicted by the Standard Model is gone? The reader might have
realized now, after this preamble, that only matter (the two electrons) is produced in
neutrinoless double-beta decay. According to many theories, the existence of this process
might be enough to explain the asymmetry between matter and anti-matter which has been
produced in the very early moments after the Big Bang. At this point, it is clear that
the search for neutrinoless double-beta decay is much more than a mere investigation of
the properties of a tiny fundamental particle. Its discovery would prove the existence of
Majorana neutrinos, physics beyond the Standard Model and perhaps shed light on the
origins of our universe.
\newpar
One of the candidate atomic nuclei for a discovery is the germanium isotope with mass
number 76. The experimental quest to discover neutrinoless double-beta decay in \gesix\
began more than fifty years ago, with the proposal by a group of researchers in
Milano~\cite{Fiorini1967}.  Germanium was already being used to build high-purity particle
detectors with excellent energy resolution, and the concept of incorporating the source in
the detector medium made the potential of this discovery channel immediately evident.
Since then, many experimental projects succeeded each other in developing the detector
technology and pushing forward the discovery sensitivity. None of them reported
unambiguous evidence for the existence of neutrinoless double-beta decay, and, in absence
of a signal, increasing lower limits on its half-life have been set. The \powtenyr{26}
threshold has been recently surpassed by the \gerda\ experiment, which is the subject of
this thesis work. \gerda\ was a \gesix\ experiment operating between 2008 and 2019 at the
Laboratori Nazionali del Gran Sasso, Italy. The core of the project was an array of forty
detectors submerged bare in liquid argon, which provided a passive and active shield
against external background, thanks to its scintillation properties. Thanks to this and
various other background mitigation techniques, \gerda\ has been operating in
background-free conditions (namely less than a background count in the neutrinoless
double-beta decay search region in the entire measurement time) for the largest part of
its collected exposure. This achievement successfully demonstrated the maturity of the
germanium technology to be the base of a next-generation, tonne-scale experiment, which is
currently prepared by the LEGEND collaboration.
\newpar
Searching for a signal in presence of a background is a common circumstance in a physics
experiment. Since the signal is hypothetical and possibly faint, the search for a signal
inevitably becomes a quest to reduce the background event rate in the search region as
much as possible. Several strategies are set up in \gerda\ both at the hardware level,
during design and construction, and at the software level, with data analysis routines.
Care is taken during the design phase not to expose the detectors to background sources
and to eventually mitigate their impact with passive or active shields. Materials for
setup items deployed in the vicinity of the detectors are then screened for the presence
of radioactive contaminants before installment. Despite all these precautions, residual
backgrounds have to expected and are indeed observed in the data. The task of the
background model is to identify the origin of these events by comparing the data collected
by the experiment to Monte Carlo simulations of radioactive contaminations in the setup.
The results are crucial to select the appropriate mitigation strategy when designing
future hardware upgrades or next-generation projects, in order to enhance the signal
sensitivity. Even data selection algorithms can benefit from an accurate knowledge of the
expected backgrounds.  Below in light blue is the energy spectrum of all events collected
by \gerda, together with the result of the background decomposition analysis, which is one
of the main subjects of this thesis.
\begin{center}
  \vspace{11pt}
  \includegraphics{plots/bkg/raw/combined-results-M1only.pdf}
\end{center}
The signature of neutrinoless double-beta decay is an event excess at the maximum energy
available in the process, indicated with a dashed line. The background model aims to give
an answer to the following questions: what kind of events dominate the background in the
region of interest? How many events from \b, \g\ and \a\ events are expected? What is
their interaction topology in the detectors? What is the source and where is it located?
Is the background flat in the region, or peak-like structures have to be expected?  What
is the correct background model to be used in the neutrinoless double-beta decay signal
search? As it is evident from the picture above, an accurate description of the
full-energy spectrum is mandatory to extract solid predictions in the region of interest.
The present thesis work aims to present and discuss the methodology developed by the
\gerda\ collaboration over the years and tries to give an answer to the questions above.
\newpar
The development of a background model in double-beta decay experiments is, nonetheless,
not only devoted to the neutrinoless signal search. The potential of the two-neutrino
decay as a precision test bench for the Standard Model and theories beyond it must not be
overlooked. A first example of new physics signal that can be searched among the
two-neutrino double-beta decay events is the so-called neutrinoless double-beta decay with
Majoron emission. In this hypothesized double-beta decay mode, two electrons are emitted
together with one or two bosonic particles that do not interact with the detector medium.
A second example is the so-called Lorentz-violating two-neutrino double-beta decay, for
which one of the fundamental assumptions of Einstein's special relativity, namely the
invariance of physics laws through all inertial frames of reference, is assumed to be
broken at some stage. Both of these hypothetical processes would produce a deformation of
the two-neutrino double-beta decay distribution (the olive green histogram in the picture
above) with respect to the Standard Model prediction. Since backgrounds contribute to
this energy region as well, an accurate model is mandatory to extract the signal
distribution and precisely study its shape.

The present thesis work is structured as follows. In \cref{chap:theory} an overview of the
double-beta decay field is given, from theory to experimental practice. The reader should
then be equipped with a basic understanding of the theory behind the standard two-neutrino
mode plus the new-physics modes and an overview of the experimental panorama.

% vim: tw=90
