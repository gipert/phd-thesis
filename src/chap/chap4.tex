%!TEX root = ../main.tex

\chapter{The background after the LAr veto cut}%
\label{chap:bkg:lar:ph2}

All what has been shown until now concerns data before the LAr and PSD cut. In this
chapter a model of the background after the LAr veto cut will be presented, based on a
Monte Carlo simulation of the LAr scintillation light propagation. Being able to describe
the background after this major event selection is indeed of great interest to study the
distribution of two-neutrino double-beta decay events, which are almost never vetoed by
the LAr veto system. As extensively shown in \cref{chap:theory}, the presence of several
new physics phenomena can be constrained by looking at the shape of the \nnbb\ events
distribution. Understanding the action of the LAr veto cut on background events from the
point of view of the background model requires, however, a full Monte Carlo simulation of
the LAr scintillation mechanism as well as the implementation of all the relevant material
and surface optical properties that contribute to light propagation in the \gerda\ experimental
setup. Implementing such a simulation, as it will be shown, requires an accurate knowledge
of many optical parameters, which is not always the case, unfortunately, with the \gerda\
setup. Nevertheless, it is possible to use special calibration data with low-activity
sources and the LAr veto instrumentation turned on to constrain the LAr veto Monte Carlo
model. An independent analysis of this special data set is used to tune the unknown
optical parameters in the Monte Carlo such to reproduce the observed vetoing performance.
The obtained parameters are then used to produce a map of the LAr scintillation light
detection probability, which is applied to the background model simulations in order to
obtain the LAr veto flag. Based on these new background model pdfs, a statistical analysis
to test possible deviations of the \nnbb\ distribution from its Standard Model description
will be finally presented in the following chapter.
\newpar
The chapter is structured as follows: \fillme{fillme}

\section{Optical physics in \mage}%
\label{sec:bkg:lar:ph2:mage}

Optical materials and surfaces are implemented in \mage\ through the relevant \geant\
libraries. Once properties like reflectivity, wavelength-shifting capabilities,
attenuation lengths, scintillation yields etc.~are defined, the \geant\ core routines take
care of simulating light propagation accordingly. When defining optical parameters in the
Monte Carlo, one must keep in mind what are the typical photon wavelengths that come to
play in the \gerda\ setup. The most important wavelength is 128~nm, in the so-called
vacuum-ultra-violet (VUV) regime, which defines the energy of the photon emitted by the
LAr scintillation process. The second interesting regime is in the 400--600~nm range,
typical of photons which are wavelength-shifted (WLS) in the fiber curtain or by
Tetraphenil-Butadiene (TPB) coatings to match the absorption range of the light detectors
(PMTs, SiPMs). As it will be clear in the next sections, many optical parameters are
poorly known in the VUV regime or depend on the details of the experimental setup (LAr
purity, WLS coating thickness etc.), and a dedicated measurement should be therefore
performed.  In the following sections a reference list of the optical properties
implemented in \mage\ is provided, with references to the literature.

\blocktitle{liquid \\ argon}
Key properties of the liquid argon from the point of view of the vetoing performance in
\gerda\ are the scintillation mechanism, the refractive index and the attenuation length.
The first two are relatively well known, while the latter strongly depends on the LAr
purity, which has not been measured for \gerda. We recall here that the deployed LAr has
not been subject to any purification process, and is therefore expected to meet the purity
specifications of natural argon.

\begin{description}

  \item[Refractive index] Its implementation depends on the photon energy (shown in
    \cref{fig:bkg:lar:ph2:mage:lar-props}). Formulas are taken from~\cite{Bideau-Mehu1981}
    and give about 1.41 at 128~nm. A more recent measurement, similarly based on an
    extrapolation of measured data to lower wavelengths, suggests a lower value of about
    1.37~\cite{Babicz2018}.

  \item[Rayleigh scattering length] Depends on the refractive index and therefore the
    photon energy (shown in \cref{fig:bkg:lar:ph2:mage:lar-props}). Formulas are taken
    from~\cite{Seidel2002}. The already implemented refractive index values are used. The
    obtained scattering length value at 128~nm is about 60~cm. The value suggested
    in~\cite{Babicz2018} is 91~cm, 50\% higher.

  \item[Scintillation spectrum] Taken from~\cite{Heindl2010}, which reports an
    experimental measurement (figs.~1 and 2). Only the (gaussian) peak is implemented in
    \mage, as the non-gaussian contributions are of several orders of magnitude lower and
    are therefore negligible. A normal distribution $(\mu=128\;\text{nm},
    \sigma=2.929\;\text{nm})$ is implemented (\cref{fig:bkg:lar:ph2:mage:lar-props}).

  \item[Scintillation yield] Different scintillation processes are defined in the \mage\
    physics list for different ionizing particles, that in general have different
    scintillation yields in LAr. A reference value of $51\;\upgamma/\text{keV}$ has been
    suggested in~\cite{Doke2002}. This value does certainly not represent the reality of
    \gerda, as the yield strongly depends on the electric field configuration and the
    quencher impurity level. Unfortunately a reliable direct measure of the scintillation
    yield of the \gerda\ LAr is not available. Indirect measurements were performed within
    the \LArGe\ setup~\cite{Lehnert2016} and with a dedicated setup deployed inside the
    \gerda\ cryostat~\cite{Barros2020}, but they both yield incompatible results. A
    tentative, default value of 28~$\upgamma/\text{keV}$ is implemented in \mage, which is
    the maximum achievable scintillation yield corresponding to 1~\mus\ triplet lifetime.
    As shown in~\cite{Doke2002}, some particles (in particular \a\ particles and nuclei)
    can be characterized by lower yields. Therefore, the photon yield is reduced for \a\
    particles and nuclei by a factor of 0.875 and 0.375 respectively in the physics list.
    These numbers are extracted from~\cite{Doke2002}. In this way \b\ and \g\ particles
    will be affected by the nominal (maximum) photon yield, while \a\ particles and nuclei
    will produce less light by a factor 0.875 and 0.375 (0.7/0.8 and 0.3/0.8 according
    to~\cite{Doke2002}), respectively.

  \item[Singlet and triplet lifetime] \sloppy The implemented triplet lifetime is the one
    measured during \gerdatwo, before the \phasetwop\ upgrade
    (\cref{fig:lar:triplet-lifetime}), the singlet lifetime \fillme{fillme}. The relative
    occurrence of the two de-excitation processes is also specified in terms of
    scintillation yield. The \geant\ \m{YIELDRATIO} property, which is defined as the
    relative strength of the fast component as a fraction of total scintillation yield, is
    set to 0.23 for all particles (\b\ and \g\ particles), 0.75 for nuclei and 1.0 for \a\
    particles (the latter is a rough guess).

  \item[Attenuation length] As the absorption length is strongly dependent on the LAr
    purity, no literature values can be used. It is known to depend on the wavelength of
    the photon in general, but this dependence is poorly known in the VUV regime. What is
    most important in \mage\ is its value at 128~nm, i.e.~the wavelength of the LAr
    scintillation light. The following, heuristic implementation is adopted: an
    exponential function is used to make sure that the LAr is opaque to VUV photons
    ($\lambda \leq 128$~nm) but transparent to wavelength-shifted photons ($\lambda
    \gtrsim 400$~nm), see fig.~\ref{fig:bkg:lar:ph2:mage:lar-props}. A measurement of the
    attenuation length in the \gerda\ LAr was performed~\cite{Barros2020}, yielding
    $\sim15$~cm as a result, but \fillme{fillme}. A default, reasonable value of 55~cm is
    implemented in \mage\ and used in the LAr veto system simulation as `best guess'.

  \item[Fano factor] A Fano factor of 0.11 is set, taken from~\cite{Doke1976}.

\end{description}

\begin{figure}
  \centering
  \includegraphics{plots/mage/lar-props.pdf}
  \caption{%
    LAr optical properties as implemented in \mage. Top left: the refractive index, top
    right: the Rayleigh absorption length, bottom left: the scintillation spectrum, bottom
    right: the absorption length. Taken from~\cite{Bideau-Mehu1981, Seidel2002,
    Heindl2010}.
  }\label{fig:bkg:lar:ph2:mage:lar-props}
\end{figure}

\blocktitle{reflectivity}
Reflectivity is another key property in optical simulations, as it can be different for
VUV scintillation photons and wavelength-shifted photons. Unfortunately, the available
literature about material reflectivity in the VUV regime is often very scarce. Surfaces
in the \gerda\ setup for which knowing the reflectivity is crucial are certainly
germanium, silicon holder plates and the VM2000 and Tetratex\reg{} reflectors that cover
the internal copper surface of the LAr veto instrumentation.

\begin{description}
  \item[Ge, Si, Cu and Teflon] Measurements performed for \gerda\ are available
    in~\cite{Wegmann2017}.  A reflectometer at room temperature and in air was used to
    measure the reflectivity in the wavelength range $[280, 700]$~nm, therefore values in
    the VUV region must be taken from other sources. For germanium it seems to strongly
    depend upon the radiation incident angle~\cite{Marton1967}, but it's not possible to
    implement angle-dependent reflectivities in \geant\ yet. A rough, average value of
    0.65 is therefore set for wavelengths smaller than 280~nm. The source of the
    reflectivity values of the other materials below 280~nm is not known to me
    \fillme{fillme}. The reflectivity values for all materials mentioned above are plot in
    \cref{fig:bkg:lar:ph2:mage:metals-refl}.

    \begin{figure}
      \centering
      \includegraphics{plots/mage/metals-refl.pdf}
      \caption{%
        Reflectivity of germanium, copper, silicon and Teflon as implemented in \mage.
      }\label{fig:bkg:lar:ph2:mage:metals-refl}
    \end{figure}

  \item[Polymeric reflectors] Tetratex\reg{} values are taken from~\cite{Janecek2012}. The
    author reports measurements of the reflectivity of 2 and 4 superimposed layers of
    160~\mum\ thick Tetratex\reg{}. As the thickness of the foils used in \gerda\ is
    254~\mum, the results for the two superimposed foils (320~\mum) are implemented in
    \mage. In reality, the reflectivity of the \gerda\ foils should be (negligibly)
    smaller. The TPB layer has some effect on the reflectivity, but there's no measurement
    available in literature.  VM2000 values are taken from~\cite{Francini2013}.  The
    authors report measurements of TPB-coated VM2000, as in the \gerda\ setup, which then
    take into account the effect of the TPB emission spectrum. The measurement seems to be
    independent on the TPB layer thickness. The values are plot in
    \cref{fig:bkg:lar:ph2:mage:misc}, left.

    \begin{figure}
      \centering
      \includegraphics{plots/mage/misc.pdf}
      \caption{%
        Reflectivity of VM2000 and Tetratex\reg{} reflectors (right) and absorption length
        of the nylon mini-shrouds (left), as implemented in \mage.
      }\label{fig:bkg:lar:ph2:mage:misc}
    \end{figure}

\end{description}

\blocktitle{wavelength \\ shifters}
Various surfaces in the \gerda\ setup are coated with a wavelength-shifting material in
order to enhance the light collection efficiency and therefore the LAr veto cut
efficiency. Tetraphenyl-Butadiene (TPB) is either evaporated on the surface pure or
embedded in a polystyrene matrix. The concerned surfaces are the nylon mini-shrouds, the
light-guiding fibers, the VM2000 and Tetratex\reg{} reflectors on the copper components of
the LAr veto instrumentation (or simply copper shrouds in the following) and the PMTs
glass window. The physical properties that define the wavelength-shifting process are the
quantum efficiencies (average number of WLS photons emitted), the emission spectrum of the
emitted WLS photons and their absorption length in the material. Since these properties
depend on the substrate and other characteristics like the thickness or the deposition
technique, multiple definitions of TPB are present in \mage. The quantum efficiency
depends on the layer thickness, so it should be measured for the specific sample. Since
these measurements are not available, an arbitrary but realistic value of 1.2 is set. The
WLS absorption length is another property for which no good data seems to be available in
the literature. The implemented values are taken from~\cite{Benson2017}
(\cref{fig:bkg:lar:ph2:mage:tpb-props}, left). Other TPB properties which are common to
all instances are the WLS emission time constant, which is set to an arbitrarily small
value of 0.01~ns and the reflectivity which should be small but not zero (set to 0.2).
The WLS emission spectrum changes upon the specific layer

\begin{description}

  \item[TPB on nylon mini-shrouds] This WLS coating consists of TPB embedded in a
    polystyrene matrix (3:7 ratio TPB:polystyrene) and diluted in toluene (1:10).  The
    solution is then brushed on the nylon. The emission spectrum has been
    measured~\cite{Walter2015} (see \cref{fig:bkg:lar:ph2:mage:tpb-props}, right) and is
    similar to the one in reported~\cite{Francini2013} (fig.~14) for TPB in polystyrene
    matrix on glass.

  \item[TPB on VM2000] The copper shroud internal reflective surface is coated with
    evaporated TPB. The emission spectrum is taken from~\cite{Francini2013}
    (\cref{fig:bkg:lar:ph2:mage:tpb-props}, right).  The authors report the measurement of
    a $\sim$160~\mum\ thick TPB layer on VM2000 at an excitation wavelength of 128~nm and
    at 87~K, the same \gerda\ experimental conditions. The major differences brought in by
    the LAr temperature are the vibronic structures that modify the shape of the spectrum.

  \item[TPB on fibers] No measurement is available here so the same emission spectrum
    defined for TPB on VM2000 is used. The TPB is evaporated.

  \item[TPB on Tetratex\reg{}] The Tetratex\reg{} is dip-coated (0.9~mg/cm$^2$, 8~\mum\
    thickness) with TPB. The emission spectrum has been measured for
    \gerda~\cite{Baudis2015a} and is reported in \cref{fig:bkg:lar:ph2:mage:tpb-props},
    right. The measured sample has a TPB surface density of 0.17~mg/cm$^2$. In principle
    the thickness affects the shape of the emission spectrum, as the efficiency of the
    reabsorption effect increases with the thickness of the layer. However, no relative
    measurements could be found at the time.

    \begin{figure}
      \centering
      \includegraphics{plots/mage/tpb-props.pdf}
      \caption{%
        Optical properties of Tetraphenyl-Butadiene (TPB) implemented in \mage. On the
        left: the attenuation length of the wavelength-shifted light. On the right:
        emission spectrum.
      }\label{fig:bkg:lar:ph2:mage:tpb-props}
    \end{figure}

\end{description}

\blocktitle{fiber shroud \\ mini-shrouds}
An essential part of the LAr veto system is the wavelength-shifting light-guiding fiber
curtain. The fibers themselves are a Saint Gobain product (BCF-91A polystyrene
fibers~\cite{FibersData}), and consist of a core and two cladding layers with different
refraction indices, to increase the light trapping efficiency, which is of about 3\%.
Photons interacting in the fiber are shifted to the green band of the optical spectrum,
guided to the endpoints and collected by the SiPMs at the top. The fibers are coated with
TPB, that shifts the VUV light to match the fiber absorption range.
\newpar
The nylon mini-shrouds have the triple role of keeping \kvz\ ions out, being transparent
to optical photons and eventually shift VUV photons to higher wavelengths. This capability
is achieved by coating them with TPB.

\begin{description}

  \item[BCF-91A polystyrene] Material of the fiber core. The data sheet from Saint
    Gobain~\cite{FibersData} reports the absorption spectrum, knowing that the fibers are
    1~mm thick one can extract the absorption length. Starting from the trivial relation:
    \[
      1 - P(E) = e^{-x/l(E)}
    \]
    where $P(E)$ is the probability (thus proportional to the absorption
    spectrum) for a photon travelling a distance $x$ to be absorbed in the
    material. Given the attenuation length $l(E)$, one can extract $l(E)$ from
    $P(E)$. By integrating over the thickness of the material $L$ one obtains:
    \[
      L \cdot (1 - P(E)) = l(E) \cdot (1 - e^{-L/l(E)})
    \]
    The problem now is that $l(E)$ cannot be extracted analytically (the expression is
    inhomogeneous). It can however be solved numerically.  Since the units are arbitrary
    because the original absorption spectrum has arbitrary units, the spectrum has been
    then rescaled to match a measurement performed at 400~nm, which yielded
    0.7~mm~\cite{Kneissl2012}. The result is shown in
    \cref{fig:bkg:lar:ph2:mage:fibers-props}, left. The emission spectrum is taken again
    from~\cite{FibersData} and shown in \cref{fig:bkg:lar:ph2:mage:fibers-props}, right.
    The absorption length is set to 3.5~m \fillme{fillme}. The WLS time constant, the
    refractive index have also been taken from~\cite{FibersData}. The quantum efficiency
    is set to 1. The two cladding layers are made of PMMA. As only the refractive index is
    important, it is set to 1.49 for the inner cladding layer and to 1.42 for the outer
    layer~\cite{FibersData}.

  \item[Nylon mini-shrouds] The refraction index is set to 1.54, constant over
    incident photon wavelength. The attenuation length values are taken
    from~\cite{Agostini2017b}, since \gerda\ is using the same material used for the
    \textsc{Borexino} balloon (\cref{fig:bkg:lar:ph2:mage:misc}, right).

    \begin{figure}
      \centering
      \includegraphics{plots/mage/fibers-props.pdf}
      \caption{%
        Absorption length and emission spectrum of the wavelength-shifted light in the
        light-guiding fibers, as implemented in \mage.
      }\label{fig:bkg:lar:ph2:mage:fibers-props}
    \end{figure}

\end{description}

\section{Simulating the LAr veto}%
\label{sec:bkg:lar:ph2:heatmap}

Simulating optical physics is notoriously a computationally intensive task, as the number
of photons to track is very high. Enabling optical processes in background model
simulations, which already take tens of thousands of CPU hours to complete, is not
feasible. To address the issue, an alternative approach to compute the LAr veto flag for
already existing simulations has been developed, based on the construction of a detection
probability map of scintillation photons in LAr. This object, which is going to be
described in this section, will be also be referred to simply as `heat map' or
`probability map' in the following.
\newpar
The first step to produce the probability map is to run a full photon-tracking simulation
of 128~nm scintillation photons in the whole LAr volume defined in \mage. An isotropic
source of VUV photons homogeneously distributed in a pre-selected LAr volume is simulated.
\mage\ allows to restrict the sampling to the volume occupied by LAr only or its
intersection with a geometric solid (e.g.~a cylinder). The photon initial energy is
sampled from a Gaussian distribution with mean 128~nm and variance 2.929~nm. After being
propagated in the implemented \gerda\ setup by the \geant\ core routines, it may hit a
LAr instrumentation sensitive volume (SiPM channel or PMT channel), whose identification
number is finally written on disk. After collecting a sufficient amount of simulated
events, the simulation output is further processed into the probability map. The
three-dimensional LAr volume implemented in \mage\ is partitioned in small boxes (or voxels),
that define a probability validity region. Events generated in a voxel are collected and
the ratio between the number of detected photons (at least one fired LAr veto channel)
over the total is computed.
\[
  p_i = \frac{n_i}{N_i} \pm \frac{1}{N_1}\sqrt{n_i \left(1 - \frac{n_i}{N_1} \right)} \;.
\]
where $n_i$ and $N_i$ are the total number of detected and simulated photons in voxel $i$,
respectively. The binomial uncertainty estimate assumes $N_i>0$ and $n_i<N_i$, which is
always the case for the voxel size considered in this study.  These probability estimates
are saved in a three-dimensional histogram, or LAr light detection probability map. The
\gerda\ Monte Carlo LAr model is thus effectively condensed in this object.
\newpar
The last step is to fold the probability map into the usual background model simulations,
for which no information derived from optical processes is available. Information about
energy depositions by \g, \b\ and \a\ particles in LAr is, in fact, available in the
simulation output and provide the starting point to compute the LAr veto flag. For a given
single energy deposition the number of generated scintillation photons $M$ is drawn from a
Poisson distribution with mean equal to the deposited amount of energy times the LAr
scintillation yield times the LAr Fano factor:
\[
  M \sim \operatorname{Poisson}(E \cdot Y \cdot F) \;.
\]
The number of detected photons is then randomly drawn from a binomial distribution with
success probability $p_k$, where $k$ labels the voxel that contains the LAr hit position,
and number of trials equal to $M$:
\[
  m \sim \operatorname{B}(M, p_k) \;.
\]
If $m>0$ the event is flagged as vetoed by the LAr instrumentation.

\blocktitle{the LAr \\ heat map}
A visualization of an example probability map is given in
\cref{fig:bkg:lar:ph2:larmap:tac}, with one-voxel wide transversal and longitudinal
slices. Voxels are colored according to their probability value: darker areas correspond
to regions in which less scintillation photons reach the LAr veto detectors and therefore
the vetoing efficiency is worse. It is worth to let the reader note how the detection
probability reaches very low values in the LAr volume enclosed by germanium detectors, as
photons get easily trapped in such a complex geometry. On the other hand, the closer to
PMTs and fibers the photons are produce, the higher their detection probability. In the
horizontal slice one can also appreciate the effect of the different SiPM channel
efficiencies, which break the rotational invariance of the map.
\begin{figure}
  \centering
  \includegraphics[width=0.9\linewidth]{plots/bkg/lar/ph2/larmodel/larmap-tac.png}
  \caption{%
    The three-dimensional LAr photon detection probability map interactive viewer.
    Two-dimensional longitudinal and transversal sections are displayed in the second and
    third pad from the left corresponding to the user pointer position on the 3D
    rendering in the first pad. Red lines mark the cut positions. A smoothing algorithm is
    applied to wash out statistical fluctuations and make the map look more homogeneous to
    the eye.
  }\label{fig:bkg:lar:ph2:larmap:tac}
\end{figure}
\newpar
As remarked in \cref{sec:bkg:lar:ph2:mage}, uncertainties on the optical specifications
implemented in \mage\ can be quite large. Properties like the LAr scintillation yield and
attenuation length, the germanium reflectivity and the TPB quantum efficiency can possibly
have a large impact on the probability map. Other crucial unknowns are the SiPM and PMT
channel efficiencies and the coverage of the fiber shroud, defined as the fraction of
lateral surface area of the curtain occupied by fiber material. Channel efficiencies
extracted from physics data cannot be used, as the simulated efficiencies account for
various other effects in the Monte Carlo and can therefore be quite different. The fiber
coverage on the other hand should be around 0.5, but there could be shrinking phenomena or
single-fiber twists in LAr which could make the real coverage significantly different.
\newpar
To understand the systematic impact of these parameters on the LAr probability map, a
dedicated Monte Carlo study has been performed. A set of representative voxels has been
selected, whose location is documented in \cref{fig:bkg:lar:ph2:larmap:dist}, rightmost
image. For each of these voxels the probability dependence on some Monte Carlo parameters
has been investigated, giving the results displayed in the remaining plots of
\cref{fig:bkg:lar:ph2:larmap:dist}. Voxels have been considered along the central array
axis (green), just outside (blue) and inside (red) the fiber shroud. Three additional
voxels have been chosen in the low-probability region inside the germanium array (black
and violet). Three properties have been taken into consideration for this study: the
germanium reflectivity, the fiber shroud coverage and the LAr absorption length. The
reflectivity has been scaled with a global factor, such that the unit value refers to the
value implemented in \mage. Two qualitatively different trends can be noticed: the
reflectivity and coverage impact is approximately linear in the considered interval, while
the absorption length acts more exponentially on probabilities. This is compatible with
the assumption that attenuation in matter generally follows an exponential law. However a
partial saturation effect seems to take place after about 40~cm, when the typical photon
free path length in the \gerda\ setup is reached. The impact of a parameter depends on the
voxel location too. As instance, the probability in the black voxel between \GD{89B} and
\GD{02D} changes drastically upon different germanium reflectivity assumptions. On the
other hand, orange and red voxel close to the fibers (where the calibration sources are)
are the most sensitive to modifications of the fiber shroud coverage.

\begin{figure}
  \centering
  \includegraphics[height=0.8\textwidth, angle=90]{plots/bkg/lar/ph2/larmodel/lar-points-position.pdf}
  \includegraphics{plots/bkg/lar/ph2/larmodel/larmap-dist.pdf}
  \caption{%
    Study of the impact of Monte Carlo parameters on LAr light detection probabilities in
    various spatial points. Each curve shows the dependence of the probability upon
    germanium reflectivity, fiber shroud coverage and LAr absorption length in the points
    shown in the rightmost scheme of the \gerda\ setup, using the same color code. The
    germanium reflectivity is scaled by a global factor, such that the unit value
    corresponds to the value implemented in \mage.
  }\label{fig:bkg:lar:ph2:larmap:dist}
\end{figure}

\section{Tuning the LAr veto model}%
\label{sec:bkg:lar:ph2:pcalib}

As already mentioned several times, the knowledge about several Monte Carlo optical
specifications is very limited. In particular, PMT and SiPM channel efficiencies are not
known and are essential to build a predictive LAr veto model. Efficiencies extracted from
physics data cannot be used directly, as the Monte Carlo efficiencies are in reality
complex objects that account for other effects. As instance, SiPM efficiencies can include
systematic effects from details of the geometry implementation of the fiber modules in
\mage. To overcome these issues, a statistical analysis has been developed to tune the
Monte Carlo parameters with physics data. A sample which is independent from the
regular \gerda\ physics data has been identified in the special calibration runs with
low-activity sources and the LAr veto instrumentation turned on. A short overview of this
analysis will be given in this section, the reader is referred to~\cite{Wiesinger2021} for
an extensive presentation of this broad subject.

\blocktitle{pcalib \\ runs}
The main characteristics of these data sets are documented in
\cref{tab:bkg:lar:ph2:pcalib-desc}: the first special run carries identification number
equal to 68 and has been performed with a \Th\ source in July 2016, while the second one
is run 76 and has been carried through in February 2017 with a \Ra\ source. Data has been
acquired with the sources \m{S2} and \m{S3} at three vertical positions at the top, middle
and bottom of the array. The lower source activity ($\mathcal{O}$(kBq)) makes it possible
to collect data with also the LAr veto instrumentation and provide a distinct setting for
an accurate data-to-Monte-Carlo comparison. Since the subject of this study are the
vetoing capabilities of the LAr system, the germanium main trigger has been maintained
during the data taking. Test pulses are also available and are used to estimate the
fraction of `random coincidences'. In these particular `false-positive' LAr-vetoed events
the physical process generating the scintillation light detected by PMTs and SiPMs is
distinct from the one triggering the germanium detectors at the same time. This can
happen, for example, if a calibration source decay product deposits some energy in the
germanium while a cosmic ray is ionizing the argon. Similarly these random coincidences
can be produced by two nuclear decays happening at the same time. A good estimate of the
random coincidences fraction in this special calibration data is crucial when comparing to
simulations, which miss this background-like component. Unfortunately, as documented in
\cref{tab:bkg:lar:ph2:pcalib-desc}, test pulse data is partly missing in run 68.

\begin{table}
  \centering
  \caption{%
    Summary of the special calibration data with active LAr veto instrumentation from runs
    68 (July 2016, \Th\ source) and 76 (February 2017, \Ra\ source). The random
    coincidences are estimated combining data from test pulses and SiPM
    traces~\cite{Wiesinger2021}.
  }\label{tab:bkg:lar:ph2:pcalib-desc}
  \begin{tabular}{lcccc}
    \toprule
    isotope      & source port & position (mm) & run time (h) & random coincidences (\%) \\
    \midrule
    \mr{6}{\Th}  &             & 8168          & 10.2         & --                       \\
                 & \m{S2}      & 8396          & 3.2          & --                       \\
                 &             & 8570          & 12.5         & --                       \\
                 \cmidrule{2-5}
                 &             & 8220          & 6.4          & $7.5 \pm 0.6$            \\
                 & \m{S3}      & 8405          & 4.3          & $7.2 \pm 1.0$            \\
                 &             & 8570          & 3.6          & $10.2 \pm 1.4$           \\
    \midrule
    \mr{6}{\Ra}  &             & 8139          & 8.9          & $12.2 \pm 0.3$           \\
                 & \m{S2}      & 8405          & 4.3          & $11.2 \pm 0.4$           \\
                 &             & 8570          & 6.9          & $12.9 \pm 0.3$           \\
                 \cmidrule{2-5}
                 &             & 8128          & 8.0          & $10.8 \pm 0.3$           \\
                 & \m{S3}      & 8292          & 3.6          & $8.9 \pm 0.4$            \\
                 &             & 8570          & 8.5          & $10.7 \pm 0.3$           \\
    \bottomrule
  \end{tabular}
\end{table}

\blocktitle{data \\ selection}
The analysis data set is constructed by applying an event cut based on the total energy
released in the germanium detectors. The selected energy regions are shown in
\cref{fig:bkg:lar:ph2:pcalib-data}: the \Tl\ FEP events ($2615 \pm 10$~keV) in run 68 and
the Compton-dominated energy region from 2204~keV \Bih\ line in run 76 are considered. The
obtained statistics is of about $2 \cdot 10^4$ events or more per source position.
\newpar
The data from the LAr instrumentation which is relevant to the comparison with the Monte
Carlo simulation consists in a set of veto flags (one for each of the 25 LAr veto
channels, i.e.~9 top PMTs, 7 bottom PMTs and 9 SiPM modules) for each germanium trigger.
The probability that a LAr veto channel is triggered in data can be written as the
convolution between a `signal' probability (the same event is responsible for both the
germanium and LAr veto triggers) and a `background' probability (the false-positive rate
from random coincidences). This convolution is simply the logic OR between the two
probabilities. The amount of random coincidences is estimated by combining data from test
pulses and SiPM traces, as documented in great detail in~\cite{Wiesinger2021}.

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{plots/bkg/lar/ph2/larmodel/pca-analysis-window.pdf}
  \caption{%
    The energy spectra of the \phasetwo\ special calibration runs. Left: run 68 (\Th),
    Monte Carlo simulation in blue and data in black. The top panel shows the energy
    distribution of the events while the top panel shows the amount of average amount of
    energy released by an event with respect to its energy. Right: run 76 (\Ra). Colored
    bands highlight the regions selected for the data analysis.
  }\label{fig:bkg:lar:ph2:pcalib-data}
\end{figure}

\blocktitle{simulations}
The calibration sources are fully implemented in \mage, with user commands to set their
vertical position, the radioactive source and therefore replicate the run 68 and 76
experimental settings (\cref{tab:bkg:lar:ph2:pcalib-desc}). Optical
processes are enabled in these special simulation runs, but since they require high
computational time photons are fully tracked only if an energy deposition is recorded in
germanium as well. The optical properties of the setup are fixed to their best values
documented in \cref{sec:bkg:lar:ph2:mage}. The two most important Monte Carlo settings
for the calibration source physics are the LAr attenuation length and the fiber shroud
coverage. As demonstrated in \cref{sec:bkg:lar:ph2:heatmap} and in
\cref{fig:bkg:lar:ph2:larmap:dist} in particular, these are the two parameters that affect
the most the LAr light detection probability in the red and orange points --- where the
calibration sources are typically deployed. The germanium reflectivity, instead, is
crucial when probing the region of the array. Changes in the LAr light yield or the TPB
quantum efficiencies produce nearly linear distortions of the probability map and can be
absorbed in the PMT and SiPM channel efficiencies.

\blocktitle{statistical \\ analysis}
The probability to detect $n$ LAr scintillation photons with the LAr veto instrumentation
includes a signal component (the light is physically correlated to the germanium signal)
and a background component from random coincidences:
\[
  \lambda[n] = \lambda_s[n] * \lambda_b[n] = \lambda_s \vee \lambda_b \;.
\]
A way to introduce an effective detection efficiency $\epsilon$ for a LAr veto channel is
by the following `binomial repopulation':
\[
  \lambda_s[m](\epsilon) = \sum_{n \geq m} \lambda_s[n] \binom{n}{m} \epsilon^m
    {(1-\epsilon)}^{n-m} \;,
\]
which is the probability, reduced by the efficiency $\epsilon \in [0,1]$, to observe $m <
n$ photons. Since the quantity of interest for this analysis is the LAr veto flag (i.e.~an
event is seen by the instrumentation or not), the probability to detect $m > 0$ photons
can be expressed as
\[
  \lambda_s(\epsilon) = 1 - \lambda[0](\epsilon)
                      = 1 - \sum_n \lambda_s[n] {(1-\epsilon)}^n
                      = 1 - \frac{1}{N_\text{tot}} \sum_n N_n {(1-\epsilon)}^n \;,
\]
where the last equality holds for the Monte Carlo simulations, in which $\lambda_s[n]$ is
just the ratio between the number of events in which $n$ photons were detected and the
total number of events: $\lambda_s[n] = N_n / N_\text{tot}$.
\newpar
A likelihood function is then constructed to match the Monte Carlo simulation output to the
special calibration data. Since each single event includes data from 25 LAr veto channels,
also the particular `detection pattern' must be taken into account. Given three channels
$A$, $B$ and $C$, for example, the pattern $\{A,C\}$ represents the occurence of a signal
in channel $A$, $C$ but not in $B$. The pattern in the example has probability $p_A
\cdot (1-p_B) \cdot p_C$, i.e.~it always probes all the channel detection probabilities
$p_i$. The full likelihood reads
\begin{equation}\label{eq:bkg:lar:ph2:pca-likelihood}
  \mathcal{L}(\vec{\epsilon}, \ldots) =
    \prod_P \operatorname{B}_{N_\text{tot}}^N \big(
      \sum_G ( \lambda_s(\vec{\epsilon}) + \sigma \cdot \Delta\lambda_s(\vec{\epsilon})) \cdot
      \lambda_b \big)
    \cdot \prod_G \operatorname{B}_{M_\text{tot}}^M (\lambda_b) \cdot
    \operatorname{G}(\sigma) \;,
\end{equation}
where the first product runs over all possible $\dim{P} = 2^{N_\text{ch}}$ patterns
($N_\text{ch}$ is the number of considered channels), the summation and the last product
run over all the pattern generator pairs $G = \{\{A,B\},\{B,C\},\ldots\}$. In the first
binomial term $\operatorname{B}^N_{N_\text{tot}}(\lambda)$, $N$ is the number of events in
which light was seen over the total $N_\text{tot}$ for a certain pattern. The same
nomenclature applies for the second binomial term
$\operatorname{B}^M_{M_\text{tot}}(\lambda)$, but now for the random coincidence data set.
The probability in the first binomial term is the product between the signal probability
for a given pattern (which is calculated by summing over all possible pattern generators)
and the background random coincidence probability $\lambda_b$. The signal probability
contains an additional contribution $\sigma \Delta\lambda_s(\vec{\epsilon})$ which
accounts for the effect of low statistics in the Monte Carlo data sample. The term is
regulated by the nuisance parameter $\sigma$, which is constrained by the pull term
$\operatorname{\sigma}$, a Gaussian distribution with null mean and variance $\sigma$. The
number of degrees of freedom of this likelihood is $2^{N_\text{ch}}-N$.
\newpar
The likelihood function is then maximized to obtain the best fit values for the parameters
of interest, the LAr veto channel efficiencies $\vec{\epsilon}$. The same likelihood
function can also be used to make some inference on other Monte Carlo optical unknowns,
e.g.~the LAr attenuation length or the fiber shroud coverage. This idea is presented and
discussed in~\cite{Wiesinger2021}, but its application is out of the scope of this work,
which requires only a rough tuning of the LAr probability map. Indeed, a broad range of
systematic map distortions which might be due to uncertain optical specifications is
tested in the framework of the \nnbb\ distribution analysis, which will be presented in
\cref{chap:2nbb-ana}.

\blocktitle{results}
Since the tuned LAr probability map will be only used to provide the LAr veto flag for the
background model simulations, which are further processed to create the pdfs for the
\bege\ summed energy spectrum, an additional simplification can be introduced in the
analysis. In principle, the array of channel efficiencies $\vec{\epsilon}$ in
\cref{eq:bkg:lar:ph2:pca-likelihood} has dimension 25, but the symmetries of the
experimental setup can be exploited to reduce the number of parameters. A cylindrical
symmetry is \emph{de facto} present in the arrangement of PMTs and SiPM modules, as shown
in the technical drawings in \cref{fig:setup:magevolumes}. This spatial symmetry is evidently
broken in the LAr veto channel efficiencies domain, since the measured signal rates are
already different one from the other, but the effect of this asymmetry has to be evaluated
on the analysis data set, i.e.~the \bege\ summed energy spectrum. Since the \bege\
detector arrangement in the array does not significantly deviate from a cylindrical
distribution, it is not expected to depend too much on differences between efficiencies of
light detectors at the same vertical height. Therefore, only three effective efficiencies
are used in \cref{eq:bkg:lar:ph2:pca-likelihood} ($N_\text{ch}=3$): one for all top PMTs,
one for all SiPM modules and one for all bottom PMTs.
\newpar
In this simplified setting, the maximization of $\mathcal{L}(\vec{\epsilon})$ yields:
\[
  \epsilon_\text{PMTt} = 0.140 \pm 0.003 \;, \quad
  \epsilon_\text{SiPM} = 0.326 \pm 0.007 \;, \quad
  \epsilon_\text{PMTb} = 0.346 \pm 0.007 \;.
\]
And the magnitude of systematic uncertainty needed to obtain a reasonable goodness of fit
($-2\Delta\log\mathcal{L}=10$) at the best fit point is around 30\%, which already shows
how this analysis suffers from the many unknown optical specifications in the Monte Carlo.
The impact of this problem on the \nnbb\ distribution analysis is addressed in
\cref{sec:2nbb-ana:systematics} through a dedicated study of the connected systematic
uncertainty.

\section{The data after the LAr veto cut}

\chapsummary
\begin{itemize}
  \item The background model pdfs after the LAr veto cut necessitates the implementation
    of the LAr veto instrumentation as well as the optical properties of all materials
    involved in the propagation of the scintillation photons into the Monte Carlo
    framework (\mage). Many of these properties are unfortunately not precisely known: the
    LAr absorption length, the channel efficiencies, the germanium reflectivity in the VUV
    light regime, among the others.
  \item The high computational time cost of the \geant\ simulations of optical processes
    require the implementation of an alternative approach to compute the LAr veto flag for
    Monte Carlo events, rather than directly enabling the optical physics in the \mage\
    simulations. A three-dimensional LAr light detection probability map is independently
    built by means of a dedicated, massive simulation of scintillation photons in the LAr.
    The map is then convoluted with the existing background model simulations to determine
    the LAr veto flag.
  \item Since the shape of the \nnbb\ distribution is nearly not affected by the LAr veto
    and the background level is low, a qualitative LAr probability map is enough in light
    of the \nnbb\ energy distribution analysis after the LAr veto cut. Special calibration
    data with LAr veto discrimination is used to determine three average detection
    efficiencies for top PMTs, SiPMs and bottom PMTs. The background model pdfs are
    expected to be negligibly affected by differences between single-channel efficiencies.
    The impact of other possible systematic uncertainties in the LAr veto modeling is
    assessed in the context of the \nnbb\ shape analysis.
  \item \fillme{fillme}
\end{itemize}

% vim: tw=90
